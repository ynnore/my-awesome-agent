# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
  - name: "python:3.11-slim"
    id: deploy-data-ingestion-pipeline-staging
    entrypoint: bash
    args:
      - -c
      - |
        cd data_ingestion && pip install uv --user && uv sync --frozen && \
        uv run python data_ingestion_pipeline/submit_pipeline.py
    env:
      - "PIPELINE_ROOT=${_PIPELINE_GCS_ROOT}"
      - "REGION=${_REGION}"
      - "DATA_STORE_REGION=${_DATA_STORE_REGION}"
      - "DATA_STORE_ID=${_DATA_STORE_ID}"
      - "PROJECT_ID=${_STAGING_PROJECT_ID}"
      - "SERVICE_ACCOUNT=${_PIPELINE_SA_EMAIL}"
      - "PIPELINE_NAME=${_PIPELINE_NAME}"
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
  # Build and Push
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
        ".",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
      ]

  # Deploy to Staging
  - name: "gcr.io/cloud-builders/gcloud"
    id: deploy-staging
    entrypoint: gcloud
    args:
      - "run"
      - "deploy"
      - "my-awesome-agent"
      - "--image"
      - "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME"
      - "--region"
      - "${_REGION}"
      - "--project"
      - "${_STAGING_PROJECT_ID}"
      - "--min-instances"
      - "1"
      - "--no-cpu-throttling"
      - "--cpu"
      - "4"
      - "--memory"
      - "4Gi"
      - "--concurrency"
      - "40"
      - "--service-account"
      - "${_CLOUD_RUN_APP_SA_NAME}@${_STAGING_PROJECT_ID}.iam.gserviceaccount.com"
      - "--set-env-vars"
      - "COMMIT_SHA=${COMMIT_SHA},DATA_STORE_ID=${_DATA_STORE_ID},DATA_STORE_REGION=${_DATA_STORE_REGION}"

  # Fetch Staging Service URL
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-staging-url
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud run services describe my-awesome-agent \
        --region ${_REGION} --project ${_STAGING_PROJECT_ID} --format="value(status.url)") > staging_url.txt

  # Fetch ID Token
  - name: gcr.io/cloud-builders/gcloud
    id: fetch-id-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-identity-token -q) > id_token.txt

  # Load Testing
  - name: "python:3.11-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _ID_TOKEN=$(cat id_token.txt)
        export _STAGING_URL=$(cat staging_url.txt)
        pip install uv --user && uv sync --frozen
        uv add locust==2.32.6
        uv run locust -f tests/load_test/load_test.py \
        --headless \
        -H $$_STAGING_URL \
        -t 30s -u 10 -r 0.5 \
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'

  # Export Load Test Results to GCS
  - name: gcr.io/cloud-builders/gcloud
    id: export-results-to-gcs
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        gsutil -m cp -r tests/load_test/.results gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}
        echo "_________________________________________________________________________"
        echo "Load test results copied to gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "HTTP link: https://console.cloud.google.com/storage/browser/${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "_________________________________________________________________________"

  # Trigger Prod Deployment
  - name: gcr.io/cloud-builders/gcloud
    id: trigger-prod-deployment
    entrypoint: gcloud
    args:
      - "beta"
      - "builds"
      - "triggers"
      - "run"
      - "deploy-to-prod-pipeline"
      - "--region"
      - "$LOCATION"
      - "--project"
      - "$PROJECT_ID"
      - "--sha"
      - $COMMIT_SHA

  - name: gcr.io/cloud-builders/gcloud
    id: echo-view-build-trigger-link
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo "_________________________________________________________________________"
        echo "Production deployment triggered. View progress and / or approve on the Cloud Build Console:"
        echo "https://console.cloud.google.com/cloud-build/builds;region=$LOCATION"
        echo "_________________________________________________________________________"

substitutions:
  _STAGING_PROJECT_ID: YOUR_STAGING_PROJECT_ID
  _BUCKET_NAME_LOAD_TEST_RESULTS: ${PROJECT_ID}-cicd-load-test-results
  _REGION: us-central1
  _DATA_STORE_REGION: us
  _PIPELINE_NAME: genai_sample_data_ingestion

logsBucket: gs://${PROJECT_ID}-logs-data/build-logs
options:
  substitutionOption: ALLOW_LOOSE
  defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET
